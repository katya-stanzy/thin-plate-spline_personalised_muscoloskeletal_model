{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import opensim as osim\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping pandas from truncating long strings\n",
    "pd.set_option('display.max_colwidth', 10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\055\\\\P55\\\\model_update'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to generic scaled model\n",
    "scaled_model = f\"../final_results/generic_scaled/scaled_model_joints.osim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the new personalized model\n",
    "new_model_name = f'tps_transformed.osim'\n",
    "path_to_model = os.path.join(\"..\", 'final_results', 'personalized')\n",
    "if not os.path.exists(path_to_model):\n",
    "    print(path_to_model)\n",
    "    os.makedirs(path_to_model)\n",
    "new_model = os.path.join(path_to_model, new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT : THESE SHOULD BE PERSON-SPECIFIC\n",
    "mass_text = '52.4'\n",
    "height_text = '1.60'\n",
    "age_text = '33'\n",
    "\n",
    "# path to experimental .trc file : <marker_file>\n",
    "experimental_markers = r'../motion_lab/static/Static03/task.trc'\n",
    "static_df = pd.read_csv(experimental_markers, delimiter='\\t', skiprows=3, header=[0,1], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tps_warping_results\\\\results'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path to TPS results\n",
    "tps_folder = os.path.join(\"..\", 'final_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Scaled Model with TPS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Transformed Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_df = pd.concat([pd.read_csv(os.path.join(tps_folder, 'pelvis_bone_markers.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'femur_l_bone_markers.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'femur_r_bone_markers.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'patella_l_bone_markers.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'patella_r_bone_markers.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'tibia_l_bone_markers.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'tibia_r_bone_markers.csv'), index_col=0)])\n",
    "markers_df = markers_df.set_index('name')\n",
    "markers_df.to_csv(os.path.join(tps_folder, 'markers_transformed.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Transformed Muscle Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mscles_df = pd.concat([pd.read_csv(os.path.join(tps_folder, 'pelvis_muscle_paths.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'femur_l_muscle_paths.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'femur_r_muscle_paths.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'patella_l_muscle_paths.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'patella_r_muscle_paths.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'tibia_l_muscle_paths.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'tibia_r_muscle_paths.csv'), index_col=0)])\n",
    "mscles_df = mscles_df.set_index('name')\n",
    "mscles_df.to_csv(os.path.join(tps_folder, 'muscles_transformed.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Transformed Wrapping Surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrp_df  = pd.concat([pd.read_csv(os.path.join(tps_folder, 'pelvis_wrap_translations.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'femur_l_wrap_translations.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'femur_r_wrap_translations.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'tibia_l_wrap_translations.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'tibia_r_wrap_translations.csv'), index_col=0)])\n",
    "wrp_df = wrp_df.set_index('name')\n",
    "wrp_df.to_csv(os.path.join(tps_folder, 'wrp_transformed.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import transformed Skin Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_df = pd.concat([pd.read_csv(os.path.join(tps_folder, 'pelvis_skin_markers.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'femur_l_skin_markers.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'femur_r_skin_markers.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'tibia_l_skin_markers.csv'), index_col=0),\n",
    "            pd.read_csv(os.path.join(tps_folder, 'tibia_r_skin_markers.csv'), index_col=0)])\n",
    "skin_df = skin_df.set_index('name')\n",
    "skin_df.to_csv(os.path.join(tps_folder, 'skin_transformed.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse current scaled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=ET.parse(scaled_model)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update reference geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_geom_dic = {'body': [], 'Mesh name' : [], 'Mesh file' : []}\n",
    "\n",
    "ref_geom_dic['body'].append(\"pelvis\"); ref_geom_dic['Mesh name'].append(\"pelvis_geom_1\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\r_pelvis.stl'))\n",
    "ref_geom_dic['body'].append(\"pelvis\"); ref_geom_dic['Mesh name'].append(\"pelvis_geom_2\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\l_pelvis.stl'))\n",
    "ref_geom_dic['body'].append(\"pelvis\"); ref_geom_dic['Mesh name'].append(\"pelvis_geom_3\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\sacrum.stl'))\n",
    "\n",
    "ref_geom_dic['body'].append(\"femur_r\"); ref_geom_dic['Mesh name'].append(\"femur_r_geom_1\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\femur_r.stl'))\n",
    "ref_geom_dic['body'].append(\"femur_l\"); ref_geom_dic['Mesh name'].append(\"femur_l_geom_1\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\femur_l.stl'))\n",
    "\n",
    "ref_geom_dic['body'].append(\"tibia_r\"); ref_geom_dic['Mesh name'].append(\"tibia_r_geom_1\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\tibia_r.stl'))\n",
    "ref_geom_dic['body'].append(\"tibia_r\"); ref_geom_dic['Mesh name'].append(\"tibia_r_geom_2\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\fibula_r.stl'))\n",
    "\n",
    "ref_geom_dic['body'].append(\"tibia_l\"); ref_geom_dic['Mesh name'].append(\"tibia_l_geom_1\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\tibia_l.stl'))\n",
    "ref_geom_dic['body'].append(\"tibia_l\"); ref_geom_dic['Mesh name'].append(\"tibia_l_geom_2\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\fibula_l.stl'))\n",
    "\n",
    "ref_geom_dic['body'].append(\"patella_r\"); ref_geom_dic['Mesh name'].append(\"patella_r_geom_1\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\patella_r.stl'))\n",
    "ref_geom_dic['body'].append(\"patella_l\"); ref_geom_dic['Mesh name'].append(\"patella_l_geom_1\"); ref_geom_dic['Mesh file'].append(os.path.join('bones\\\\patella_l.stl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_geom_df = pd.DataFrame(ref_geom_dic).set_index('Mesh name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Mesh in root.iter('Mesh'):\n",
    "    point = Mesh.attrib['name']\n",
    "    if point in ref_geom_df.index:\n",
    "        new_text = ref_geom_df.loc[point, 'Mesh file']\n",
    "        # print(point, new_text)\n",
    "        Mesh.find('mesh_file').text = new_text\n",
    "        Mesh.find('scale_factors').text = '1 1 1'\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update muscle paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "muscle_path_names = []\n",
    "muscle_path_old = []\n",
    "muscle_path_new = []\n",
    "\n",
    "for PathPoint in root.iter('PathPoint'):\n",
    "    point = PathPoint.attrib['name']   \n",
    "    if point in mscles_df.index:      \n",
    "        \n",
    "        location = mscles_df.loc[point, 'location']\n",
    "        new_text = location[1:-1]\n",
    "        muscle_path_names.append(point)\n",
    "        muscle_path_new.append(new_text)\n",
    "        muscle_path_old.append(PathPoint.find('location').text)\n",
    "\n",
    "        PathPoint.find('location').text = new_text\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "muscle_path_new_df = pd.DataFrame([[float(i) for i in point.split()] for point in muscle_path_new], index=muscle_path_names, columns=['x','y','z'])\n",
    "muscle_path_old_df = pd.DataFrame([[float(i) for i in point.split()] for point in muscle_path_old], index=muscle_path_names, columns=['x','y','z'])\n",
    "\n",
    "muscle_path_diff_df = muscle_path_old_df - muscle_path_new_df\n",
    "muscle_path_diff_df['d'] = (muscle_path_diff_df['x']**2+muscle_path_diff_df['y']**2+muscle_path_diff_df['z']**2)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update muscle wrapping surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_cyl_name = []\n",
    "wrap_transl_old = []\n",
    "wrap_transl_new = []\n",
    "wrap_radius_old = []\n",
    "wrap_radius_new = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for WrapCylinder in root.iter('WrapCylinder'):\n",
    "    point = WrapCylinder.attrib['name']\n",
    "    wrap_cyl_name.append(point)\n",
    "\n",
    "    if point in wrp_df.index:\n",
    "        translation = wrp_df.loc[point, 'location']\n",
    "        wrap_transl_new.append(translation)\n",
    "        wrap_transl_old.append(WrapCylinder.find('translation').text)\n",
    "        WrapCylinder.find('translation').text = translation[1:-1]\n",
    "\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Translation of joint centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torso_origin_in_pelvis = markers_df.loc['torso_origin_in_pelvis', 'location']\n",
    "\n",
    "femur_r_center_in_pelvis = markers_df.loc['femur_r_center_in_pelvis', 'location']\n",
    "femur_l_center_in_pelvis = markers_df.loc['femur_l_center_in_pelvis', 'location']\n",
    "knee_l_center_in_femur = markers_df.loc['knee_l_center_in_femur_l', 'location']\n",
    "knee_r_center_in_femur = markers_df.loc['knee_r_center_in_femur_r', 'location']\n",
    "patella_l_center_in_femur = markers_df.loc['patella_l_in_femur_l', 'location']\n",
    "patella_r_center_in_femur = markers_df.loc['patella_r_in_femur_r', 'location']\n",
    "\n",
    "talus_l_center_in_tibia = markers_df.loc['talus_l_center_in_tibia', 'location']\n",
    "talus_r_center_in_tibia = markers_df.loc['talus_r_center_in_tibia', 'location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_centers_names = []\n",
    "joint_centers_new = []\n",
    "joint_centers_old = []\n",
    "\n",
    "for joint in root.iter('CustomJoint'):\n",
    "    \n",
    "    name = joint.attrib['name']\n",
    "    if joint.attrib['name'] ==  \"back\":\n",
    "        for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "            if frame.attrib['name'] == \"pelvis_offset\":\n",
    "                new_text = torso_origin_in_pelvis[1:-1]\n",
    "                joint_centers_names.append(\"back\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)\n",
    "                frame.find('translation').text = new_text\n",
    "\n",
    "            else: pass\n",
    "\n",
    "    if joint.attrib['name'] ==  \"hip_r\":\n",
    "        for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "            if frame.attrib['name'] == \"pelvis_offset\":                \n",
    "                new_text = femur_r_center_in_pelvis[1:-1]\n",
    "                joint_centers_names.append(\"hip_r\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)           \n",
    "                frame.find('translation').text = new_text\n",
    "\n",
    "            else: pass\n",
    "    \n",
    "    elif joint.attrib['name'] ==  \"hip_l\":\n",
    "        for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "            if frame.attrib['name'] == \"pelvis_offset\":\n",
    "                new_text = femur_l_center_in_pelvis[1:-1]\n",
    "                joint_centers_names.append(\"hip_l\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)\n",
    "                frame.find('translation').text = new_text\n",
    "            else: pass\n",
    "            \n",
    "    elif joint.attrib['name'] ==  \"walker_knee_r\":\n",
    "        for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "            if frame.attrib['name'] == \"femur_r_offset\":\n",
    "                new_text = knee_r_center_in_femur[1:-1]\n",
    "                joint_centers_names.append(\"walker_knee_r\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)\n",
    "                frame.find('translation').text = new_text\n",
    "\n",
    "            #if frame.attrib['name'] == \"tibia_r_offset\":\n",
    "            #    new_text = f\"{walker_knee_r_tibia_r_offset[0]}, {walker_knee_r_tibia_r_offset[1]}, {walker_knee_r_tibia_r_offset[2]}\"\n",
    "            #    frame.find('translation').text = new_text\n",
    "            else: pass    \n",
    "    \n",
    "    elif joint.attrib['name'] ==  \"walker_knee_l\":\n",
    "        for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "            if frame.attrib['name'] == \"femur_l_offset\":\n",
    "                new_text = knee_l_center_in_femur[1:-1]\n",
    "                joint_centers_names.append(\"walker_knee_l\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)\n",
    "                frame.find('translation').text = new_text\n",
    "\n",
    "    #        if frame.attrib['name'] == \"tibia_l_offset\":\n",
    "    #            new_text = f\"{walker_knee_l_tibia_l_offset[0]}, {walker_knee_l_tibia_l_offset[1]}, {walker_knee_l_tibia_l_offset[2]}\"\n",
    "    #            frame.find('translation').text = new_text\n",
    "            else: pass\n",
    "\n",
    "    elif joint.attrib['name'] ==  \"patellofemoral_r\":\n",
    "       for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "           if frame.attrib['name'] == \"femur_r_offset\":               \n",
    "                new_text = knee_r_center_in_femur[1:-1]\n",
    "                joint_centers_names.append(\"patellofemoral_r\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)\n",
    "                frame.find('translation').text = new_text\n",
    "           else: pass\n",
    "    \n",
    "    elif joint.attrib['name'] ==  \"patellofemoral_l\":\n",
    "       for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "           if frame.attrib['name'] == \"femur_l_offset\":              \n",
    "                new_text = knee_l_center_in_femur[1:-1]\n",
    "                joint_centers_names.append(\"patellofemoral_l\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)\n",
    "                frame.find('translation').text = new_text\n",
    "           else: pass\n",
    "\n",
    "for joint in root.iter('PinJoint'):   \n",
    "    name = joint.attrib['name']\n",
    "    if joint.attrib['name'] ==  \"ankle_r\":\n",
    "       for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "           if frame.attrib['name'] == \"tibia_r_offset\":              \n",
    "                new_text = talus_r_center_in_tibia [1:-1]\n",
    "                joint_centers_names.append(\"ankle_r\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)\n",
    "                frame.find('translation').text = new_text\n",
    "           else: pass\n",
    "    \n",
    "    elif joint.attrib['name'] ==  \"ankle_l\":\n",
    "       for frame in joint.iter('PhysicalOffsetFrame'):\n",
    "           if frame.attrib['name'] == \"tibia_l_offset\":              \n",
    "                new_text = talus_r_center_in_tibia [1:-1]              \n",
    "                joint_centers_names.append(\"ankle_r\")\n",
    "                joint_centers_new.append(new_text)\n",
    "                joint_centers_old.append(frame.find('translation').text)              \n",
    "                frame.find('translation').text = new_text\n",
    "           else: pass\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Markers for Joint Positions in Parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_names = ['torso_origin_in_pelvis','femur_l_center_in_pelvis', 'femur_r_center_in_pelvis',  'knee_l_center_in_femur_l', 'patella_l_in_femur_l', 'knee_r_center_in_femur_r', 'patella_r_in_femur_r']\n",
    "\n",
    "for marker in root.iter('Marker'):\n",
    "    name = marker.attrib['name']\n",
    "    if name == 'ankle_l_tibia_l_offset':\n",
    "        old_text = marker.find('location').text\n",
    "        new_text = markers_df.loc['talus_l_center_in_tibia', 'location']\n",
    "        marker.find('location').text = new_text[1:-1]\n",
    "    elif name == 'ankle_r_tibia_r_offset':\n",
    "        old_text = marker.find('location').text\n",
    "        new_text = markers_df.loc['talus_r_center_in_tibia', 'location']\n",
    "        marker.find('location').text = new_text[1:-1]\n",
    "    elif name in m_names:\n",
    "        old_text = marker.find('location').text\n",
    "        new_text = markers_df.loc[name, 'location']\n",
    "        marker.find('location').text = new_text[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uldate Skin Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symmetrize skin markers\n",
    "str2lst = lambda x: [y for y in x.strip('[]').split() if y != '']\n",
    "R_xy = [[1,  0,  0],\n",
    "        [0,  1,  0],\n",
    "        [0,  0, -1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skin_pelvis = skin_df.loc[skin_df['body'] == 'pelvis', 'location'].apply(str2lst)\n",
    "skin_pelvis_reflected = skin_pelvis.copy()\n",
    "skin_pelvis_reflected['RASI'], skin_pelvis_reflected['LASI'] = skin_pelvis['LASI'], skin_pelvis['RASI']\n",
    "skin_pelvis_reflected['RPSI'], skin_pelvis_reflected['LPSI'] = skin_pelvis['LPSI'],skin_pelvis['RPSI']\n",
    "skin_pelvis_reflected['PE02'], skin_pelvis_reflected['PE03'] = skin_pelvis['PE03'], skin_pelvis['PE02']\n",
    "\n",
    "pelvis_symmetric = ((skin_pelvis.apply(lambda x: np.array(x, dtype=float))).to_numpy() + \\\n",
    "(skin_pelvis_reflected.apply(lambda x: (np.array(x, dtype=float)@np.array(R_xy)))).to_numpy())*0.5\n",
    "\n",
    "skin_pelvis_symmetric = pd.DataFrame(pelvis_symmetric, index=skin_pelvis.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_femur_r = skin_df.loc[skin_df['body'] == 'femur_r', 'location'].apply(str2lst)\n",
    "skin_femur_l = skin_df.loc[skin_df['body'] == 'femur_l', 'location'].apply(str2lst)\n",
    "\n",
    "femur_r_symmetric = ((skin_femur_r.apply(lambda x: np.array(x, dtype=float))).to_numpy() + \\\n",
    "                     (skin_femur_l.apply(lambda x: (np.array(x, dtype=float)@np.array(R_xy)))).to_numpy())*0.5\n",
    "skin_femur_r_symmetric = pd.DataFrame(femur_r_symmetric, index=skin_femur_r.index)\n",
    "\n",
    "femur_l_symmetric = ((skin_femur_l.apply(lambda x: np.array(x, dtype=float))).to_numpy() + \\\n",
    "                     (skin_femur_r.apply(lambda x: (np.array(x, dtype=float)@np.array(R_xy)))).to_numpy())*0.5\n",
    "skin_femur_l_symmetric = pd.DataFrame(femur_l_symmetric, index=skin_femur_l.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_tibia_r = skin_df.loc[skin_df['body'] == 'tibia_r', 'location'].apply(str2lst)\n",
    "skin_tibia_l = skin_df.loc[skin_df['body'] == 'tibia_l', 'location'].apply(str2lst)\n",
    "\n",
    "tibia_r_symmetric = ((skin_tibia_r.apply(lambda x: np.array(x, dtype=float))).to_numpy() + \\\n",
    "                     (skin_tibia_l.apply(lambda x: (np.array(x, dtype=float)@np.array(R_xy)))).to_numpy())*0.5\n",
    "skin_tibia_r_symmetric = pd.DataFrame(tibia_r_symmetric, index=skin_tibia_r.index)\n",
    "\n",
    "tibia_l_symmetric = ((skin_tibia_l.apply(lambda x: np.array(x, dtype=float))).to_numpy() + \\\n",
    "                     (skin_tibia_r.apply(lambda x: (np.array(x, dtype=float)@np.array(R_xy)))).to_numpy())*0.5\n",
    "skin_tibia_l_symmetric = pd.DataFrame(tibia_l_symmetric, index=skin_tibia_l.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_symm_df = pd.concat([skin_pelvis_symmetric, skin_femur_r_symmetric,skin_femur_l_symmetric,skin_tibia_r_symmetric, skin_tibia_l_symmetric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for marker in root.iter('Marker'):\n",
    "    name = marker.attrib['name']\n",
    "    if name in list(skin_df.index):\n",
    "        old_text = marker.find('location').text\n",
    "        new_text = f\"{skin_symm_df.loc[name][0][0]} {skin_symm_df.loc[name][0][1]} {skin_symm_df.loc[name][0][2]}\"\n",
    "        marker.find('location').text = new_text\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export transformed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.write(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale muscle fibres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fibre_scale_script import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define models\n",
    "# generic_model = '../templates/RajagopalModified_generic_copy.osim'\n",
    "# model_to_update = f'final_results/tps_transformed.osim'\n",
    "# updated_model = f'final_results/tps_fibres_updated.osim'\n",
    "\n",
    "# # run scripts\n",
    "# osimModel_opt, SimInfo = optimMuscleParams(generic_model, model_to_update, 2, 'final_results/logging')\n",
    "\n",
    "# # printing the optimized model\n",
    "# osimModel_opt.printToXML(updated_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move bone surfaces to the new model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bones_folder = os.path.join(path_to_model, 'bones')\n",
    "os.makedirs(bones_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tps_warping_results\\results\\femur_l.stl 4_tps-bones-muscles-updated\\bones\\femur_l.stl\n",
      "tps_warping_results\\results\\femur_r.stl 4_tps-bones-muscles-updated\\bones\\femur_r.stl\n",
      "tps_warping_results\\results\\fibula_l.stl 4_tps-bones-muscles-updated\\bones\\fibula_l.stl\n",
      "tps_warping_results\\results\\fibula_r.stl 4_tps-bones-muscles-updated\\bones\\fibula_r.stl\n",
      "tps_warping_results\\results\\l_pelvis.stl 4_tps-bones-muscles-updated\\bones\\l_pelvis.stl\n",
      "tps_warping_results\\results\\patella_l.stl 4_tps-bones-muscles-updated\\bones\\patella_l.stl\n",
      "tps_warping_results\\results\\patella_r.stl 4_tps-bones-muscles-updated\\bones\\patella_r.stl\n",
      "tps_warping_results\\results\\r_pelvis.stl 4_tps-bones-muscles-updated\\bones\\r_pelvis.stl\n",
      "tps_warping_results\\results\\sacrum.stl 4_tps-bones-muscles-updated\\bones\\sacrum.stl\n",
      "tps_warping_results\\results\\tibia_l.stl 4_tps-bones-muscles-updated\\bones\\tibia_l.stl\n",
      "tps_warping_results\\results\\tibia_r.stl 4_tps-bones-muscles-updated\\bones\\tibia_r.stl\n"
     ]
    }
   ],
   "source": [
    "# this code moves the bones from the TPS folder to the bones folder\n",
    "import shutil\n",
    "for file in os.listdir(tps_folder):\n",
    "    if file.endswith('.stl'):\n",
    "        old_path = os.path.join(tps_folder, file)\n",
    "        new_path = os.path.join(bones_folder, file)\n",
    "        print(old_path, new_path)\n",
    "        shutil.copy(old_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit skin markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save skin markers to markers.xml\n",
    "skin_model = osim.Model(new_model)\n",
    "skin_model.initSystem()\n",
    "\n",
    "# Get the marker set\n",
    "marker_set = skin_model.getMarkerSet()\n",
    "cloned_marker_set = marker_set.clone()\n",
    "cloned_marker_set.printToXML(os.path.join(path_to_model, 'markers.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit Skin Markers\n",
    "# <model_file>\n",
    "model = new_model # f'final_results/tps_fibres_updated.osim'\n",
    "\n",
    "# <time_range>'\n",
    "time_range = f' 0 {list(static_df.loc[static_df.shape[0], \"Time\"])[0] }'\n",
    "\n",
    "# <output_scale_file>\n",
    "path_to_model = '4_tps-bones-muscles-updated'\n",
    "output_scale_file = os.path.join(path_to_model, f'{ind}_marker_placer.txt')\n",
    "output_scaling_settings = os.path.join(path_to_model, f'{ind}_marker_placer.xml')\n",
    "output_model_file = os.path.join(path_to_model, f'{ind}_tps_skin_updated.osim')\n",
    "\n",
    "# <marker_set_file>\n",
    "path_to_marker_set = os.path.join(path_to_model, 'markers.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the .xml with markers in body frames\n",
    "scaling_tree=ET.parse(\"../templates/marker_placer.xml\")\n",
    "scaling_root = scaling_tree.getroot()\n",
    "\n",
    "for generic_model in scaling_root.iter('model_file'):\n",
    "    generic_model.text = model\n",
    "for generic_marker_set in scaling_root.iter('marker_set_file'):\n",
    "    generic_marker_set.text = path_to_marker_set\n",
    "\n",
    "for exp_markers in scaling_root.iter('marker_file'):\n",
    "    exp_markers.text = experimental_markers\n",
    "\n",
    "for time in scaling_root.iter('time_range'):\n",
    "    time.text = time_range\n",
    "for output in scaling_root.iter('output_model_file'):\n",
    "    output.text = output_model_file\n",
    "for scale in scaling_root.iter('output_scale_file'):\n",
    "    scale.text = output_scale_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_tree.write(output_scaling_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simFunctions import runProgram\n",
    "\n",
    "cmdprog = 'opensim-cmd'\n",
    "cmdtool = 'run-tool'\n",
    "cmdfile = output_scaling_settings\n",
    "cmdfull = [cmdprog, cmdtool, cmdfile]\n",
    "rc = runProgram(cmdfull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Wrapping Surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrap_scripts import *\n",
    "\n",
    "model_to_update = output_model_file\n",
    "updated_model = os.path.join(path_to_model, f'{ind}_tps_skin_wrp_updated.osim')\n",
    "\n",
    "# function to extract muscle paths, wrapping surfaces info and joint info from an osim model\n",
    "# returns three dataframes: muscles, surfaces and joints\n",
    "fix_wraps = FixWraps(model_to_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrp_adjust_dict = fix_wraps.collect_wrp_details()\n",
    "wrp_adjust_df = pd.DataFrame.from_dict(wrp_adjust_dict)\n",
    "wrp_adjust_df.set_index(pd.Index(['body', 'transl', 'rad', 'point_label', 'point', 'point_body', 'joint_location', 'joint_location+point', 'dist_to_transl',  'dist']), inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrp_adjust_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print points whose location is too far into radius for an automatic adjustment\n",
    "manual = []\n",
    "for col in wrp_adjust_df.columns:\n",
    "    if wrp_adjust_df.loc['dist', col] < wrp_adjust_df.loc['rad', col]-0.005:\n",
    "        print(col, ':', wrp_adjust_df.loc['point_label', col])\n",
    "        manual.append(col)\n",
    "\n",
    "# ignore patella points for now\n",
    "# adjust other points or wrapping surfaces manually for the input model and run the script again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # update model\n",
    "tree_model = ET.parse(model_to_update)\n",
    "root = tree_model.getroot()\n",
    "\n",
    "wrp_to_change = [i for i in wrp_adjust_df.columns if i not in manual]\n",
    "\n",
    "for WrapCylinder in root.iter('WrapCylinder'):\n",
    "    name = WrapCylinder.attrib['name']\n",
    "    if name in wrp_to_change:\n",
    "        print(name)\n",
    "        radius = wrp_adjust_df.loc['rad', name]\n",
    "        print('old_radius', radius)\n",
    "        new_rad = wrp_adjust_df.loc['dist', name]\n",
    "        print('new_radius', new_rad)\n",
    "        radius_new_text = str(new_rad-0.01)\n",
    "        WrapCylinder.find('radius').text = radius_new_text\n",
    "\n",
    "tree_model.write(updated_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
